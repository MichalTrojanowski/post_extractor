{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt ZTNBD\n",
    "\n",
    "## Lokalna instalacja\n",
    "###### Wymagania\n",
    "- docker\n",
    "- ~4GB wolnego miejsca na dysku\n",
    "- zalecany linux + build-essential\n",
    "\n",
    "###### Linux \n",
    "```bash\n",
    "make notebook\n",
    "```\n",
    "###### Others (nie sprawdzane)\n",
    "```bash\n",
    "# lokalizacja - główny katalogu projektu\n",
    "docker run -it --rm -v $(pwd):/home/jovyan/work -p 8888:8888 jupyter/pyspark-notebook\n",
    "```\n",
    "\n",
    "Komenda startuje kontener dockerowy z Jupyterem i podmontowuje katalog projektu.\n",
    "Moduły znajdują się w katalogu `modules` i tam też będą lądowały kolejne.\n",
    "Uruchomienie póki co możliwe jest tylko z poziomu notebook'a.\n",
    "\n",
    "## Moduły\n",
    "\n",
    "##### PostTransformer\n",
    "Klasa PostTransformer dziedziczy po klasach pyspark.ml.Transformer, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol. Posiada metodę transform, która przyjmuje na wejściu obiekt typu dataframe. Metoda ta wydobywa z kolumny inputCol, z formatu json, content i umieszcza go w kolumnie outputCol w postaci tekstu.\n",
    "##### TranslateTransformer\n",
    "Klasa TranslateTransformer dziedziczy po klasach pyspark.ml.Transformer, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol. Posiada metodę transform, która przyjmuje na wejściu obiekt typu dataframe. Metoda ta tłumaczy tekst zawarty w kolumnie inputCol  z języka polskiego na angielski i umieszcza go w kolumnie outputCol.\n",
    "##### SentenceTransformer\n",
    "Klasa SentenceTransformer dziedziczy po klasach pyspark.ml.Transformer, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol. Posiada metodę transform, która przyjmuje na wejściu obiekt typu dataframe. Metoda ta dzieli tekst zawarty w kolumnie inputCol  na zdania i umieszcza go w kolumnie outputCol w postaci tablicy tekstów.\n",
    "##### SpeechPartsTransformer\n",
    "Klasa SpeechPartsTransformer dziedziczy  po klasach pyspark.ml.Transformer, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol. Posiada metodę transform, która przyjmuje na wejściu obiekt typu dataframe. Metoda ta z tekstu zawartego w kolumnie inputCol  zlicza wystąpienie części mowy i wstawia do outputCol w postaci jsona.\n",
    "##### SentimentTransformer\n",
    "Klasa SentimentTransformer dziedziczy  po klasach pyspark.ml.Transformer, pyspark.ml.param.shared.HasInputCol, pyspark.ml.param.shared.HasOutputCol. Posiada metodę transform, która przyjmuje na wejściu obiekt typu dataframe. Metoda ta z tekstu zawartego w kolumnie inputCol  wylicza sentiment i wstawia do kolumny outputCol.\n",
    "\n",
    "## Dokumentacja\n",
    "[Google Docs](https://docs.google.com/document/d/1IylTvJbRe8s_j_bZqbM-6nWVa2IQDjQiZx-NyJsGZbg)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.6/site-packages (from textblob)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob)\n",
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!python -m textblob.download_corpora lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from modules.posts import (\n",
    "    SentenceTransformer, PostTransformer, TranslateTransformer,\n",
    "    SpeechPartsTransformer, SentimentTransformer\n",
    ")\n",
    "from modules.features import (\n",
    "    FeaturesTransformer,\n",
    "    MeanFeaturesTransformer,\n",
    "    MedianFeaturesTransformer,\n",
    "    NumberOfOccurrencesFeaturesTransformer\n",
    ")\n",
    "\n",
    "sc = SparkContext('local[*]', 'PipelineFlow')\n",
    "sess = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(spark_context):\n",
    "    rdd = spark_context.wholeTextFiles('data/featuresample.json')\n",
    "    rdd = rdd.map(lambda x: (x[0], x[1]))\n",
    "    df = rdd.toDF(['file', 'content'])\n",
    "\n",
    "    features = [\n",
    "        \"leaf\",\n",
    "        \"has-attribute-class\",\n",
    "    ]\n",
    "    \n",
    "    feature_transformer = FeaturesTransformer(features=features)\n",
    "    feature_transformer.setInputCol('content').setOutputCol('features')\n",
    "    \n",
    "    mean_feature_transformer = MeanFeaturesTransformer(features=features)\n",
    "    mean_feature_transformer.setInputCol('content').setOutputCol('mean')\n",
    "    \n",
    "    median_feature_transformer = MedianFeaturesTransformer(features=features)\n",
    "    median_feature_transformer.setInputCol('content').setOutputCol('median')\n",
    "    \n",
    "    number_of_occurences_feature_transformer = NumberOfOccurrencesFeaturesTransformer(features=features)\n",
    "    number_of_occurences_feature_transformer.setInputCol('content').setOutputCol('number_of_occurences')\n",
    "    \n",
    "    stages = [\n",
    "        feature_transformer,\n",
    "        mean_feature_transformer,\n",
    "        median_feature_transformer,\n",
    "        number_of_occurences_feature_transformer,\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    result = pipeline.fit(df).transform(df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+\n",
      "|            features|                mean|    median|number_of_occurences|\n",
      "+--------------------+--------------------+----------+--------------------+\n",
      "|[1.14285714285714...|[1.14285714285714...|[1.0, 1.0]|              [7, 4]|\n",
      "+--------------------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(mean=['1.1428571428571428', '1.0'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = transform_features(sc)\n",
    "result.select('features', 'mean', 'median', 'number_of_occurences').show()\n",
    "result.select('mean').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_posts(spark_context):\n",
    "    rdd = spark_context.wholeTextFiles('data/posts/*')\n",
    "    rdd = rdd.map(lambda x: (x[0], json.loads(x[1])))\n",
    "    df = rdd.toDF(['file', 'content'])\n",
    "    \n",
    "    poster = PostTransformer()\n",
    "    poster.setInputCol('content').setOutputCol('posts')\n",
    "    \n",
    "    translator = TranslateTransformer()\n",
    "    translator.setInputCol('posts').setOutputCol('translated')\n",
    "    \n",
    "    sentencer = SentenceTransformer()\n",
    "    sentencer.setInputCol('translated').setOutputCol('sentences')\n",
    "    \n",
    "    speech_parter = SpeechPartsTransformer()\n",
    "    speech_parter.setInputCol('translated').setOutputCol('speechParts')\n",
    "    \n",
    "    sentimenter = SentimentTransformer()\n",
    "    sentimenter.setInputCol('translated').setOutputCol('sentiments')\n",
    "\n",
    "    stages = [\n",
    "        poster,\n",
    "        translator, \n",
    "        sentencer, \n",
    "        speech_parter, \n",
    "        sentimenter\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    result = pipeline.fit(df).transform(df)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transform_posts(sc)\n",
    "\n",
    "def sample_output(out):\n",
    "    a = out.select('sentences').first().sentences[0]\n",
    "    b = out.select('sentences').first().sentences[1]\n",
    "    c = out.select('sentences').first().sentences[2]\n",
    "    d = out.select('translated').first().translated[0]\n",
    "    e = out.select('speechParts').first().speechParts\n",
    "    f = out.select('sentiments').first().sentiments[0]\n",
    "    g = out.select('sentiments').first().sentiments[1]\n",
    "    h = out.select('sentiments').first().sentiments[2]\n",
    "    scheme = '{}\\n\\n{}\\n\\n{}\\n\\n{}\\n\\n{}\\n\\n{}\\n\\n{}\\n\\n{}'\n",
    "    print(scheme.format(a,b,c,d,e,f,g,h))\n",
    "\n",
    "out.select('sentences', 'translated', 'speechParts', 'sentiments').show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
